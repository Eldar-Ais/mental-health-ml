# Анализ факторов психического здоровья сотрудников IT

Учебный проект по машинному обучению.  
Цель — проанализировать факторы, связанные с обращением сотрудников за лечением психического здоровья, и построить модель классификации уровня риска.

Проект охватывает полный цикл работы с данными:

- загрузка и предобработка сырых анкетных данных;
- разведочный анализ (EDA) с визуализациями;
- построение и обучение нескольких моделей классификации;
- оценка качества по нескольким метрикам;
- анализ важности признаков и интерпретация результатов.

---

## Описание проекта

В проекте используется открытый датасет [Mental Health in Tech Survey (Kaggle)](https://www.kaggle.com/datasets/osmi/mental-health-in-tech-survey).  
Каждая строка — анонимный ответ сотрудника IT-сферы о его психическом состоянии, условиях работы и наличии поддержки со стороны работодателя.

### Цель анализа

Определить, какие факторы (личные и рабочие) связаны с повышенным риском ухудшения психического здоровья и обращением за лечением, а также построить модель, которая:

- по анкете сотрудника предсказывает, относится ли он к группе риска (`treatment = 1`);
- показывает, какие признаки вносят наибольший вклад в решение модели.

### Краткое описание датасета

- **Количество записей после фильтрации:** ~1250 сотрудников  
- **Основные группы признаков:**
  - демографические (возраст, пол, страна);
  - рабочие условия (удалёнка, размер компании, наличие льгот, влияние работы на психическое состояние);
  - отношение к психическому здоровью (готовность обсуждать с коллегами, руководством, знание вариантов помощи);
- **Целевая переменная:**  
  - `treatment = 0` — сотрудник не обращался за лечением;  
  - `treatment = 1` — сотрудник обращался за лечением.

---

### Основные шаги проекта

#### 1. Предобработка данных

На этом этапе выполняются:

- фильтрация по возрасту (оставляем только сотрудников от 18 до 65 лет);
- нормализация пола: создание признака `Gender_clean` (male / female / other);
- преобразование целевой переменной `treatment` из строковых значений `Yes/No` в числовые `1/0`;
- заполнение пропусков:
  - категориальные признаки → значение `"Unknown"`;
  - числовые признаки → медиана;
- кодирование категориальных признаков с помощью **One-Hot Encoding**;
- масштабирование числовых признаков с помощью **StandardScaler**.

**Зачем это нужно:**

- модели не умеют напрямую работать со строками — категориальные признаки нужно закодировать;
- пропуски могут ломать обучение и смещать статистику;
- нормализация числовых признаков улучшает сходимость и устойчивость таких моделей, как Logistic Regression и SVM.

---

#### 2. Разведочный анализ данных (EDA)

В рамках EDA выполняется:

- анализ распределения возраста и целевой переменной `treatment`;
- сравнение групп по признакам `family_history`, `work_interfere`, `care_options`, размеру компании;
- построение гистограмм, boxplot, barplot;
- построение корреляционной матрицы признаков;
- визуализация ROC-кривых для обученных моделей.

**Некоторые наблюдения:**

- сотрудники старше 30 лет чаще относятся к группе `treatment = 1`;
- наличие семейной истории психических заболеваний увеличивает вероятность обращения за лечением;
- один из ключевых признаков — `work_interfere` (насколько работа мешает психическому состоянию);
- знание вариантов помощи (`care_options`) также связано с увеличением обращений (люди, которые знают, куда обратиться, делают это чаще).

---

#### 3. Модели машинного обучения

В проекте используются три модели классификации:

1. **Logistic Regression**
2. **Decision Tree Classifier**
3. **SVM (RBF kernel)**

Обучение организовано через `Pipeline`:

- препроцессинг (масштабирование + one-hot encoding);
- модель (одна из трёх).

Данные разделяются на обучающую и тестовую выборки с помощью `train_test_split` с параметром `stratify=y`.

---

#### 4. Оценка качества

Для оценки качества моделей используются следующие метрики:

- **Accuracy** — доля правильных ответов:
  - `Accuracy = (TP + TN) / (TP + TN + FP + FN)`
- **Precision** (точность положительного класса):
  - `Precision = TP / (TP + FP)`
- **Recall** (полнота, чувствительность):
  - `Recall = TP / (TP + FN)`
- **F1-score** — гармоническое среднее Precision и Recall:
  - `F1 = 2 * Precision * Recall / (Precision + Recall)`
- **ROC AUC** — площадь под ROC-кривой.

Где:
- `TP` — True Positive (реальный риск, правильно предсказан);
- `TN` — True Negative (нет риска, модель это правильно определила);
- `FP` — False Positive (ложная тревога);
- `FN` — False Negative (пропущенный риск).

**Важный акцент:**  
в задачах психического здоровья особенно важен **Recall** — важно не пропускать людей, которые потенциально нуждаются в помощи. Поэтому при сравнении моделей приоритет отдаётся Recall и F1-score, а не только Accuracy.

---

### Используемые модели и мотивация выбора

#### Logistic Regression

**Почему:**  
- базовая линейная модель, хорошо подходит как отправная точка;
- выдаёт вероятности принадлежности к классу (риск обращения);
- легко интерпретировать веса признаков.

**Идея модели:**  
Модель аппроксимирует вероятность по формуле:

> `p(y=1|x) = 1 / (1 + exp(-(w^T x + b)))`

Где `w` — веса признаков, `b` — смещение.

---

#### Decision Tree

**Почему:**  
- хорошо работает с категориальными признаками после OHE;
- улавливает нелинейные связи и взаимодействия факторов;
- даёт интерпретируемые правила («если работа мешает и есть семейная история, риск выше»);
- в этом проекте показала **лучшие метрики (Accuracy, Recall, F1)**.

**Идея модели:**  
Дерево последовательно делит пространство признаков, выбирая признаки и пороги так, чтобы максимизировать критерий информативности (например, Information Gain или уменьшение Gini impurity).

---

#### SVM (RBF kernel)

**Почему:**  
- мощная модель для задач с нелинейной границей разделения;
- позволяет проверить, улучшится ли качество при более сложной разделяющей поверхности.

**Особенности:**  
после One-Hot Encoding признаков размерность пространства становится большой, SVM может становиться чувствительной к шуму и параметрам регуляризации. В этом проекте она показала качество ниже, чем Decision Tree, но всё ещё использовалась как важный ориентир.

---

### Сравнение моделей

(цифры — пример, возьми из своего `model_metrics.csv`)

| Модель               | Accuracy | Recall | F1-score | ROC AUC |
|----------------------|----------|--------|----------|---------|
| Logistic Regression  | 0.69     | 0.65   | 0.70     | 0.72    |
| Decision Tree        | **0.81** | **0.85** | **0.83** | **0.78+** |
| SVM (RBF)            | 0.68     | 0.66   | 0.69     | 0.88    |

**Вывод:**  
лучшей моделью для данной задачи стала **Decision Tree**, так как она даёт высокий Recall и F1-score и при этом остаётся интерпретируемой.

---

## Структура проекта

```text
src/
  mental_health_project.py   # основной скрипт анализа и обучения моделей
data/
  survey.csv                 # исходный датасет (НЕ добавляется в репозиторий)
plots/
  *.png                      # автоматически сохраняемые графики (EDA, ROC, важность признаков)
reports/
  presentation/              # материалы презентации (PDF/PowerPoint, при необходимости)
README.md                    # описание проекта (этот файл)
requirements.txt             # список зависимостей
.gitignore                   # исключаемые из Git файлы/папки
LICENSE (опционально)        # лицензия проекта
